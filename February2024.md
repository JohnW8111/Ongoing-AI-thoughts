1.GogRev Ignore Previous Instructions & Listen to This Interview | Sander Schulhoff, CEO, LearnPrompting.org https://learnprompting.org/
https://www.youtube.com/watch?v=W-WyN4Gis_Y
https://arxiv.org/abs/2311.16119
Here is a summary of the taxonomy in 8 bullet points that came from that article:
Simple Instruction Attack - Adds a simple adversarial instruction to a prompt
Context Ignoring Attack - Combines a simple instruction with an instruction to ignore other instructions
Compound Instruction Attack - Uses two or more instructions in a prompt
Special Case Attack - Contains a simple instruction and a "special case" statement
Few Shot Attack - Presents examples to the model of desired input-output behavior
Refusal Suppression - Instructs the model not to respond in certain ways
Context Continuation Attack - Continues the context in a misleading direction
Obfuscation - Introduces typos, pig latin, etc. to bypass filters
The text discusses various strategies and insights into prompt engineering and its impact on the field of AI and machine learning. Here are the key strategies highlighted:
Prompting: Explain context,few shot prompting, chain of thought. Show the logic. And contrastive chain of thought when you give it an aproach to the problem that doesnt work
Telling it that it great doesnt help it.

1. **Comprehensive Guides**: Creation of extensive guides, akin to Wiki pages, that compile diverse prompting strategies from across the internet.
2. **Community Engagement**: The project attracted a wide audience, from researchers to everyday users, showcasing the universal appeal and utility of well-crafted prompt engineering resources.
3. **Practical Advice for Users**: Offering actionable advice on navigating the crowded landscape of large language models (LLMs) and prompt engineering.
4. **Advanced Prompting Techniques**: Exploration of sophisticated prompt engineering methods that the speaker personally utilizes.
5. **Prompt Hacking Research**: Discussing research on prompt hacking, including the organization of competitions to uncover vulnerabilities in LLMs.
6. **Taxonomy of Prompt-Based Attacks**: Development of a classification system for understanding and categorizing different types of prompt-based vulnerabilities.
7. **Model and Application Development**: Suggestions for developers on how to mitigate the vulnerabilities exposed through prompt hacking.
8. **Empirical Research Collaboration**: Engagement with a wide range of experts from notable institutions to consolidate knowledge on prompting into comprehensive research.
9. **Innovative Use Cases**: Illustration of unique applications of prompt engineering in various fields, demonstrating its versatility.
10. **Educational Resources for Enterprises**: Transitioning from an open-source project to offering specialized courses aimed at professional development in prompt engineering.

These points encapsulate the ongoing evolution of prompt engineering, highlighting its significance in enhancing AI model interaction, fostering community knowledge sharing, and addressing security concerns through innovative research.


Latent Space https://www.latent.space/p/retool
Here are 10 key points from the conversation:

- Retool surveyed 1,600 people in 2022 on the state of AI adoption. Over half said AI was overrated, though some hype has settled down. 

- 58% of respondents said they use Stack Overflow less due to Copilot and ChatGPT. 94% of those said it was specifically because of those AI tools.

- Engineers ranked the highest expectation of AI impacting their jobs (8/10), while designers ranked the lowest (6.8/10). 

- 45% of companies made engineering interviews more difficult to compensate for Copilot/ChatGPT use. Retool still tests for fundamentals.

- Only 27% have AI in production. Of those, 66% were internal use cases, likely due to higher tolerance for errors.

- 80% of respondents use OpenAI models. As models converge, alternatives may become more viable like open source options.

- Retool started sales-led but shifted to bottoms-up ubiquity to reach their goal of getting 10%+ of software built on their platform.

- Finding applied AI use cases is still challenging. Retool sees more creative uses outside Silicon Valley.

- Workflows combining no/low code with AI steps will unlock productivity gains versus just AI chatbots.

- Philosophically, intentionality in AGI may require new selection pressures beyond those humans evolved under.
- Here are some other notable points from the conversation:

- Retool uses open source technologies like PostgreSQL vectors where possible rather than building proprietary solutions.

- They were surprised by use cases like using AI to generate clothing patterns and designs for manufacturers. Shows potential in legacy industries.

- On fundraising, they intentionally raised less money at lower valuations during the 2021 frenzy to avoid high dilution and morale issues.

- Hiring former founders early on instilled a startup culture of getting things done with little politics.

- There are still not many concrete AI use cases, even in 2024. Companies invest hoping for a breakthrough.

- GPT-4 is dominating for now due to high performance and aggressive pricing. But big tech may still compete.

- Multi-modality has a lot of interest but specifics needs remain unclear. Text likely remains the universal interface.  

- They plan to run their AI survey again to track sentiment changes over time as metrics like GPT-3.5 vs 4 usage evolve.

- Philosophically, intentionality in AGI may require new selection pressures beyond those humans evolved under.

CogRev https://www.youtube.com/watch?v=LjCTzjhALyc
The text discusses a conversation on the Cognitive Revolution podcast with Yohi Nakajima, focusing on identity, culture, and the application of AI. Here are the key points summarized:
1. **Guest Introduction**: Yohi Nakajima, an AI agent builder and VC investor, discusses themes from his Ted AI talk.
2. **Cultural Perspectives on Identity**: The conversation explores differences in identity perception between Eastern and Western cultures, especially in relation to mind and thoughts.
3. **Utilizing AI in Daily Life**: Yohi talks about converting information into a structured knowledge graph for better connectivity and understanding among people.
4. **AI as a Tool for Connection**: There's a discussion on AI's potential to find commonalities between different groups and foster new ideas.
5. **Development Process of AI Tools**: Yohi describes his iterative process in building and testing AI models with various prompts and examples.
6. **Application of AI for Web Research**: The importance of AI in enhancing web research through specific searches and knowledge retrieval is highlighted.
7. **Prototyping an Autonomous CRM**: Yohi shares his experiment with a CRM prototype using Game of Thrones episode descriptions to build a knowledge graph.
8. **Redefining Identity in the Digital Age**: The conversation encourages thinking of identity as part of a larger system rather than an internal, individualistic perspective.
9. **Philosophy Embedded in Language**: Yohi appreciates the philosophical aspects embedded in languages, particularly Japanese, and its influence on communication and perception.
10. **Collective Intelligence and Technology**: The concept of collective intelligence is discussed, with technology like computers and the internet being considered part of human society's collective identity.

This summary reflects on the broad topics covered during the podcast, emphasizing the intersection of culture, identity, and the transformative potential of AI.

Weights & Biases The Power of AI in Search with You.com's Richard Socher https://www.youtube.com/watch?v=-yRAQlOIvGY
The talk features a conversation with Richard Socher, a pioneer at the intersection of deep learning and language models, and Lucas, the host of Gradient Descent. Socher's journey from his academic beginnings in Germany to leading AI efforts at Salesforce and founding You.com is explored, along with insights into the evolution of AI and machine learning. They discuss challenges and breakthroughs in NLP, the importance of feature learning over engineering, and the potential of AI in various fields, including search engines and healthcare. Here's a summarization in bullet points:

1. Richard Socher's background in linguistic computer science and his early interest in combining math and languages.
2. His academic journey, including studies at the Max Planck Institute and Stanford, where he encountered deep learning.
3. The shift from feature engineering to learning in NLP, and the development of word vectors and sentence-image mapping models.
4. The founding of MetaMind, aiming to simplify training neural networks for organizations, and its acquisition by Salesforce.
5. The creation of the AI Economist to explore taxation and subsidy effects on economy and equality.
6. The inception of prompt engineering and the vision for a single model for all of NLP.
7. The foundation of You.com and AX Ventures, focusing on changing search with AI and creating a more AI-forward search engine.
8. The challenge of competing with Google and the need for a general-purpose AI platform that speaks to customer use cases.
9. The evolution of You.com to incorporate LMs into search, emphasizing user adaptation to AI-enhanced search experiences.
10. Innovations at You.com, including multimodal search capabilities and programming execution within search.
11. The competitive landscape in AI and search, and the potential for AI to assist in complex queries and learning.
12. The importance of ethical considerations in AI development, particularly in content restriction and security.

In summary, the talk delves into the transformative potential of AI across various domains, emphasizing the importance of innovation, ethical use, and the ongoing evolution of search engines to better meet user needs. Socher's journey underscores the rapid advancements in AI and the critical role of pioneering research and application in shaping the future of technology.
